{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "israeli-spyware",
   "metadata": {},
   "source": [
    "## Build your own training/testing split\n",
    "\n",
    "#### Date: 2021.10.07\n",
    "\n",
    "When working with machine learning data, splitting into a \"train\", \"dev\" (or validation) and \"test\") set is important. Models use **train** data to learn representations and update their parameters; **dev** or validation data is reserved to see how the model may perform on unknown predictions. While it may not be explicitly trained on, it can be used as a stopping criteria, for hyper-parameter tuning, or as a simple sanity check. Lastly, **test** data is always reserved, hidden from the model, as a final pass to see what models perform best.\n",
    "\n",
    "Lightwood supports a variety of **encoders** (Feature engineering procedures) and **mixers** (predictor algorithms that go from feature vectors to the target). Given the diversity of algorithms, it is appropriate to split data into these three categories when *preparing* encoders or *fitting* mixers.\n",
    "\n",
    "Our default approach stratifies labeled data to ensure your train, validation, and test sets are equally represented in all classes. However, in many instances you may want a custom technique to build your own splits. We've included the `splitter` functionality (default found in `lightwood.data.splitter`) to enable you to build your own.\n",
    "\n",
    "In the following problem, we shall work with a Kaggle dataset around credit card fraud (found [here](https://www.kaggle.com/mlg-ulb/creditcardfraud)). Fraud detection is difficult because the events we are interested in catching are thankfully rare events. Because of that, there is a large **imbalance of classes** (in fact, in this dataset, less than 1% of the data are the rare-event).\n",
    "\n",
    "In a supervised technique, we may want to ensure our training data sees the rare event of interest. A random shuffle could potentially miss rare events. We will implement **SMOTE** to increase the number of positive classes in our training data.\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "interim-discussion",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-07T23:57:49.012379Z",
     "iopub.status.busy": "2022-07-07T23:57:49.011806Z",
     "iopub.status.idle": "2022-07-07T23:57:52.666595Z",
     "shell.execute_reply": "2022-07-07T23:57:52.665809Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO:lightwood-2404:No torchvision detected, image helpers not supported.\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2404:No torchvision/pillow detected, image encoder not supported\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Lightwood modules\n",
    "import lightwood as lw\n",
    "from lightwood import ProblemDefinition, \\\n",
    "                      JsonAI, \\\n",
    "                      json_ai_from_problem, \\\n",
    "                      code_from_json_ai, \\\n",
    "                      predictor_from_code\n",
    "\n",
    "import imblearn # Vers 0.5.0 minimum requirement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decimal-techno",
   "metadata": {},
   "source": [
    "### 1) Load your data\n",
    "\n",
    "Lightwood works with `pandas` DataFrames. We can use pandas to load our data. Please download the dataset from the above link and place it in a folder called `data/` where this notebook is located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "foreign-orchestra",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-07T23:57:52.671817Z",
     "iopub.status.busy": "2022-07-07T23:57:52.671177Z",
     "iopub.status.idle": "2022-07-07T23:57:59.421513Z",
     "shell.execute_reply": "2022-07-07T23:57:59.420793Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "data = pd.read_csv(\"https://mindsdb-example-data.s3.eu-west-2.amazonaws.com/jupyter/creditcard.csv.zip\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rental-contribution",
   "metadata": {},
   "source": [
    "We see **31 columns**, most of these columns appear numerical. Due to confidentiality reasons, the Kaggle dataset mentions that the columns labeled $V_i$ indicate principle components (PCs) from a PCA analysis of the original data from the credit card company. There is also a \"Time\" and \"Amount\", two original features that remained. The time references time after the first transaction in the dataset, and amount is how much money was considered in the transaction. \n",
    "\n",
    "You can also see a heavy imbalance in the two classes below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cathedral-mills",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-07T23:57:59.425544Z",
     "iopub.status.busy": "2022-07-07T23:57:59.425132Z",
     "iopub.status.idle": "2022-07-07T23:57:59.777642Z",
     "shell.execute_reply": "2022-07-07T23:57:59.776790Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Distribution of Classes')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f = plt.figure()\n",
    "ax = f.add_subplot(1,1,1)\n",
    "ax.hist(data['Class'], bins = [-0.1, 0.1, 0.9, 1.1], log=True)\n",
    "ax.set_ylabel(\"Log Counts\")\n",
    "ax.set_xticks([0, 1])\n",
    "ax.set_xticklabels([\"0\", \"1\"])\n",
    "ax.set_xlabel(\"Class\")\n",
    "ax.set_title(\"Distribution of Classes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exact-timeline",
   "metadata": {},
   "source": [
    "### 2) Create a JSON-AI default object\n",
    "We will now create JSON-AI syntax for our problem based on its specifications. We can do so by setting up a ``ProblemDefinition``. The ``ProblemDefinition`` allows us to specify the target, the column we intend to predict, along with other details. \n",
    "\n",
    "The end goal of JSON-AI is to provide **a set of instructions on how to compile a machine learning pipeline*.\n",
    "\n",
    "Our target here is called \"**Class**\", which indicates \"0\" for no fraud and \"1\" for fraud. We'll generate the JSON-AI with the minimal syntax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "medieval-zambia",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-07T23:57:59.781840Z",
     "iopub.status.busy": "2022-07-07T23:57:59.781359Z",
     "iopub.status.idle": "2022-07-07T23:59:08.137286Z",
     "shell.execute_reply": "2022-07-07T23:59:08.136613Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO:lightwood-2404:Analyzing a sample of 18424\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2404:from a total population of 284807, this is equivalent to 6.5% of your data.\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2404:Infering type for: Time\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2404:Column Time has data type integer\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2404:Infering type for: V1\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2404:Column V1 has data type float\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2404:Infering type for: V2\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2404:Column V2 has data type float\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2404:Infering type for: V3\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2404:Column V3 has data type float\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2404:Infering type for: V4\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2404:Column V4 has data type float\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2404:Infering type for: V5\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2404:Column V5 has data type float\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2404:Infering type for: V6\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2404:Column V6 has data type float\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2404:Infering type for: V7\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2404:Column V7 has data type float\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2404:Infering type for: V8\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2404:Column V8 has data type float\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2404:Infering type for: V9\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2404:Column V9 has data type float\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2404:Infering type for: V10\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2404:Column V10 has data type float\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2404:Infering type for: V11\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2404:Column V11 has data type float\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2404:Infering type for: V12\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2404:Column V12 has data type float\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2404:Infering type for: V13\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2404:Column V13 has data type float\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2404:Infering type for: V14\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2404:Column V14 has data type float\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2404:Infering type for: V15\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2404:Column V15 has data type float\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2404:Infering type for: V16\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2404:Column V16 has data type float\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2404:Infering type for: V17\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2404:Column V17 has data type float\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2404:Infering type for: V18\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2404:Column V18 has data type float\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2404:Infering type for: V19\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2404:Column V19 has data type float\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2404:Infering type for: V20\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2404:Column V20 has data type float\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2404:Infering type for: V21\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2404:Column V21 has data type float\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2404:Infering type for: V22\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2404:Column V22 has data type float\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2404:Infering type for: V23\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2404:Column V23 has data type float\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2404:Infering type for: V24\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2404:Column V24 has data type float\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2404:Infering type for: V25\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2404:Column V25 has data type float\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2404:Infering type for: V26\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2404:Column V26 has data type float\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2404:Infering type for: V27\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2404:Column V27 has data type float\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2404:Infering type for: V28\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2404:Column V28 has data type float\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2404:Infering type for: Amount\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2404:Column Amount has data type float\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2404:Infering type for: Class\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2404:Column Class has data type binary\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2404:Starting statistical analysis\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2404:Finished statistical analysis\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Setup the problem definition\n",
    "problem_definition = {\n",
    "    'target': 'Class',\n",
    "}\n",
    "\n",
    "# Generate the j{ai}son syntax\n",
    "json_ai = json_ai_from_problem(data, problem_definition)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deadly-rotation",
   "metadata": {},
   "source": [
    "Lightwood looks at each of the many columns and indicates they are mostly float, with exception of \"**Class**\" which is binary.\n",
    "\n",
    "You can observe the JSON-AI if you run the command `print(json_ai.to_json())`. Given there are many input features, we won't print it out."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "immune-clone",
   "metadata": {},
   "source": [
    "These are the only elements required to get off the ground with JSON-AI. However, we're interested in making a *custom* approach. So, let's make this syntax a file, and introduce our own changes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "massive-divide",
   "metadata": {},
   "source": [
    "### 3) Build your own splitter module\n",
    "\n",
    "For Lightwood, the goal of a splitter is to intake an initial dataset (pre-processed ideally, although you can run the pre-processor on each DataFrame within the splitter) and return a dictionary with the keys \"train\", \"test\", and \"dev\" (at minimum). Subsequent steps of the pipeline expect the keys \"train\", \"test\", and \"dev\", so it's important you assign datasets to these as necessary. \n",
    "\n",
    "We're going to introduce SMOTE sampling in our splitter. SMOTE allows you to quickly learn an approximation to make extra \"samples\" that mimic the undersampled class. \n",
    "\n",
    "We will use the package `imblearn` and `scikit-learn` to quickly create a train/test split and apply SMOTE to our training data only.\n",
    "\n",
    "**NOTE** This is simply an example of things you can do with the splitter; whether SMOTE sampling is ideal for your problem depends on the question you're trying to answer!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4411ee53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-07T23:59:08.141415Z",
     "iopub.status.busy": "2022-07-07T23:59:08.141016Z",
     "iopub.status.idle": "2022-07-07T23:59:08.147463Z",
     "shell.execute_reply": "2022-07-07T23:59:08.146789Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing MyCustomSplitter.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile MyCustomSplitter.py\n",
    "\n",
    "from lightwood.api.dtype import dtype\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List, Dict\n",
    "from itertools import product\n",
    "from lightwood.api.types import TimeseriesSettings\n",
    "from lightwood.helpers.log import log\n",
    "\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def MySplitter(\n",
    "    data: pd.DataFrame,\n",
    "    target: str,\n",
    "    pct_train: float = 0.8,\n",
    "    pct_dev: float = 0.1,\n",
    "    seed: int = 1,\n",
    ") -> Dict[str, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Custom splitting function\n",
    "\n",
    "\n",
    "    :param data: Input data\n",
    "    :param target: Name of the target\n",
    "    :param pct_train: Percentage of data reserved for training, taken out of full data\n",
    "    :param pct_dev: Percentage of data reserved for dev, taken out of train data\n",
    "    :param seed: Random seed for reproducibility\n",
    "\n",
    "    :returns: A dictionary containing the keys train, test and dev with their respective data frames.\n",
    "    \"\"\"\n",
    "\n",
    "    # Shuffle the data\n",
    "    data = data.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "\n",
    "    # Split into feature columns + target\n",
    "    X = data.iloc[:, data.columns != target]  # .values\n",
    "    y = data[target]  # .values\n",
    "\n",
    "    # Create a train/test split\n",
    "    X2, X_test, y2, y_test = train_test_split(\n",
    "        X, y, train_size=pct_train, random_state=seed, stratify=data[target]\n",
    "    )\n",
    "\n",
    "    X_train, X_dev, y_train, y_dev = train_test_split(\n",
    "        X2, y2, test_size=pct_dev, random_state=seed, stratify=y2\n",
    "    )\n",
    "\n",
    "    # Create a SMOTE model and bump up underbalanced class JUST for train data\n",
    "    SMOTE_model = SMOTE(random_state=seed)\n",
    "\n",
    "    Xtrain_mod, ytrain_mod = SMOTE_model.fit_resample(X_train, y_train.ravel())\n",
    "\n",
    "    Xtrain_mod[target] = ytrain_mod\n",
    "    X_test[target] = y_test\n",
    "    X_dev[target] = y_dev\n",
    "\n",
    "    return {\"train\": Xtrain_mod, \"test\": X_test, \"dev\": X_dev}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "analyzed-radical",
   "metadata": {},
   "source": [
    "#### Place your custom module in `~/lightwood_modules`\n",
    "\n",
    "We automatically search for custom scripts in your `~/lightwood_modules` path. Place your file there. Later, you'll see when we autogenerate code, that you can change your import location if you choose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34092d12",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-07T23:59:08.151217Z",
     "iopub.status.busy": "2022-07-07T23:59:08.150858Z",
     "iopub.status.idle": "2022-07-07T23:59:08.154630Z",
     "shell.execute_reply": "2022-07-07T23:59:08.153950Z"
    }
   },
   "outputs": [],
   "source": [
    "from lightwood import load_custom_module\n",
    "\n",
    "load_custom_module('MyCustomSplitter.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lucky-blair",
   "metadata": {},
   "source": [
    "### 4) Introduce your custom splitter in JSON-AI\n",
    "\n",
    "Now let's introduce our custom splitter. JSON-AI keeps a lightweight syntax but fills in many default modules (like splitting, cleaning).\n",
    "\n",
    "For the custom cleaner, we'll work by editing the \"splitter\" key. We will change properties within it as follows:\n",
    "(1) \"module\" - place the name of the function. In our case it will be \"MyCustomCleaner.cleaner\"\n",
    "(2) \"args\" - any keyword argument specific to your cleaner's internals. \n",
    "\n",
    "This will look as follows:\n",
    "```\n",
    "    \"splitter\": {\n",
    "        \"module\": \"MyCustomSplitter.MySplitter\",\n",
    "        \"args\": {\n",
    "            \"data\": \"data\",\n",
    "            \"target\": \"$target\",\n",
    "            \"pct_train\": 0.8,\n",
    "            \"pct_dev\": 0.1,\n",
    "            \"seed\": 1\n",
    "        }\n",
    "    },\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "identical-georgia",
   "metadata": {},
   "source": [
    "### 5) Generate Python code representing your ML pipeline\n",
    "\n",
    "Now we're ready to load up our custom JSON-AI and generate the predictor code!\n",
    "\n",
    "We can do this by first reading in our custom json-syntax, and then calling the function `code_from_json_ai`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "alleged-concentrate",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-07T23:59:08.157878Z",
     "iopub.status.busy": "2022-07-07T23:59:08.157530Z",
     "iopub.status.idle": "2022-07-07T23:59:08.588647Z",
     "shell.execute_reply": "2022-07-07T23:59:08.587946Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO:lightwood-2404:Unable to import black formatter, predictor code might be a bit ugly.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import lightwood\n",
      "from lightwood import __version__ as lightwood_version\n",
      "from lightwood.analysis import *\n",
      "from lightwood.api import *\n",
      "from lightwood.data import *\n",
      "from lightwood.encoder import *\n",
      "from lightwood.ensemble import *\n",
      "from lightwood.helpers.device import *\n",
      "from lightwood.helpers.general import *\n",
      "from lightwood.helpers.log import *\n",
      "from lightwood.helpers.numeric import *\n",
      "from lightwood.helpers.imputers import *\n",
      "from lightwood.helpers.parallelism import *\n",
      "from lightwood.helpers.seed import *\n",
      "from lightwood.helpers.text import *\n",
      "from lightwood.helpers.torch import *\n",
      "from lightwood.mixer import *\n",
      "import pandas as pd\n",
      "from typing import Dict, List, Union\n",
      "import os\n",
      "from types import ModuleType\n",
      "import importlib.machinery\n",
      "import sys\n",
      "import time\n",
      "\n",
      "\n",
      "for import_dir in [\n",
      "    os.path.join(\n",
      "        os.path.expanduser(\"~/lightwood_modules\"), lightwood_version.replace(\".\", \"_\")\n",
      "    ),\n",
      "    os.path.join(\"/etc/lightwood_modules\", lightwood_version.replace(\".\", \"_\")),\n",
      "]:\n",
      "    if os.path.exists(import_dir) and os.access(import_dir, os.R_OK):\n",
      "        for file_name in list(os.walk(import_dir))[0][2]:\n",
      "            if file_name[-3:] != \".py\":\n",
      "                continue\n",
      "            mod_name = file_name[:-3]\n",
      "            loader = importlib.machinery.SourceFileLoader(\n",
      "                mod_name, os.path.join(import_dir, file_name)\n",
      "            )\n",
      "            module = ModuleType(loader.name)\n",
      "            loader.exec_module(module)\n",
      "            sys.modules[mod_name] = module\n",
      "            exec(f\"import {mod_name}\")\n",
      "\n",
      "\n",
      "class Predictor(PredictorInterface):\n",
      "    target: str\n",
      "    mixers: List[BaseMixer]\n",
      "    encoders: Dict[str, BaseEncoder]\n",
      "    ensemble: BaseEnsemble\n",
      "    mode: str\n",
      "\n",
      "    def __init__(self):\n",
      "        seed(1)\n",
      "        self.target = \"Class\"\n",
      "        self.mode = \"inactive\"\n",
      "        self.problem_definition = ProblemDefinition.from_dict(\n",
      "            {\n",
      "                \"target\": \"Class\",\n",
      "                \"pct_invalid\": 2,\n",
      "                \"unbias_target\": True,\n",
      "                \"seconds_per_mixer\": 57024.0,\n",
      "                \"seconds_per_encoder\": None,\n",
      "                \"expected_additional_time\": 68.3439462184906,\n",
      "                \"time_aim\": 259200,\n",
      "                \"target_weights\": None,\n",
      "                \"positive_domain\": False,\n",
      "                \"timeseries_settings\": {\n",
      "                    \"is_timeseries\": False,\n",
      "                    \"order_by\": None,\n",
      "                    \"window\": None,\n",
      "                    \"group_by\": None,\n",
      "                    \"use_previous_target\": True,\n",
      "                    \"horizon\": None,\n",
      "                    \"historical_columns\": None,\n",
      "                    \"target_type\": \"\",\n",
      "                    \"allow_incomplete_history\": True,\n",
      "                    \"eval_cold_start\": True,\n",
      "                    \"interval_periods\": [],\n",
      "                },\n",
      "                \"anomaly_detection\": False,\n",
      "                \"use_default_analysis\": True,\n",
      "                \"ignore_features\": [],\n",
      "                \"fit_on_all\": True,\n",
      "                \"strict_mode\": True,\n",
      "                \"seed_nr\": 1,\n",
      "            }\n",
      "        )\n",
      "        self.accuracy_functions = [\"balanced_accuracy_score\"]\n",
      "        self.identifiers = {}\n",
      "        self.dtype_dict = {\n",
      "            \"Time\": \"integer\",\n",
      "            \"V1\": \"float\",\n",
      "            \"V2\": \"float\",\n",
      "            \"V3\": \"float\",\n",
      "            \"V4\": \"float\",\n",
      "            \"V5\": \"float\",\n",
      "            \"V6\": \"float\",\n",
      "            \"V7\": \"float\",\n",
      "            \"V8\": \"float\",\n",
      "            \"V9\": \"float\",\n",
      "            \"V10\": \"float\",\n",
      "            \"V11\": \"float\",\n",
      "            \"V12\": \"float\",\n",
      "            \"V13\": \"float\",\n",
      "            \"V14\": \"float\",\n",
      "            \"V15\": \"float\",\n",
      "            \"V16\": \"float\",\n",
      "            \"V17\": \"float\",\n",
      "            \"V18\": \"float\",\n",
      "            \"V19\": \"float\",\n",
      "            \"V20\": \"float\",\n",
      "            \"V21\": \"float\",\n",
      "            \"V22\": \"float\",\n",
      "            \"V23\": \"float\",\n",
      "            \"V24\": \"float\",\n",
      "            \"V25\": \"float\",\n",
      "            \"V26\": \"float\",\n",
      "            \"V27\": \"float\",\n",
      "            \"V28\": \"float\",\n",
      "            \"Amount\": \"float\",\n",
      "            \"Class\": \"binary\",\n",
      "        }\n",
      "\n",
      "        # Any feature-column dependencies\n",
      "        self.dependencies = {\n",
      "            \"Class\": [],\n",
      "            \"Time\": [],\n",
      "            \"V1\": [],\n",
      "            \"V2\": [],\n",
      "            \"V3\": [],\n",
      "            \"V4\": [],\n",
      "            \"V5\": [],\n",
      "            \"V6\": [],\n",
      "            \"V7\": [],\n",
      "            \"V8\": [],\n",
      "            \"V9\": [],\n",
      "            \"V10\": [],\n",
      "            \"V11\": [],\n",
      "            \"V12\": [],\n",
      "            \"V13\": [],\n",
      "            \"V14\": [],\n",
      "            \"V15\": [],\n",
      "            \"V16\": [],\n",
      "            \"V17\": [],\n",
      "            \"V18\": [],\n",
      "            \"V19\": [],\n",
      "            \"V20\": [],\n",
      "            \"V21\": [],\n",
      "            \"V22\": [],\n",
      "            \"V23\": [],\n",
      "            \"V24\": [],\n",
      "            \"V25\": [],\n",
      "            \"V26\": [],\n",
      "            \"V27\": [],\n",
      "            \"V28\": [],\n",
      "            \"Amount\": [],\n",
      "        }\n",
      "\n",
      "        self.input_cols = [\n",
      "            \"Time\",\n",
      "            \"V1\",\n",
      "            \"V2\",\n",
      "            \"V3\",\n",
      "            \"V4\",\n",
      "            \"V5\",\n",
      "            \"V6\",\n",
      "            \"V7\",\n",
      "            \"V8\",\n",
      "            \"V9\",\n",
      "            \"V10\",\n",
      "            \"V11\",\n",
      "            \"V12\",\n",
      "            \"V13\",\n",
      "            \"V14\",\n",
      "            \"V15\",\n",
      "            \"V16\",\n",
      "            \"V17\",\n",
      "            \"V18\",\n",
      "            \"V19\",\n",
      "            \"V20\",\n",
      "            \"V21\",\n",
      "            \"V22\",\n",
      "            \"V23\",\n",
      "            \"V24\",\n",
      "            \"V25\",\n",
      "            \"V26\",\n",
      "            \"V27\",\n",
      "            \"V28\",\n",
      "            \"Amount\",\n",
      "        ]\n",
      "\n",
      "        # Initial stats analysis\n",
      "        self.statistical_analysis = None\n",
      "        self.ts_analysis = None\n",
      "        self.runtime_log = dict()\n",
      "\n",
      "    @timed\n",
      "    def analyze_data(self, data: pd.DataFrame) -> None:\n",
      "        # Perform a statistical analysis on the unprocessed data\n",
      "\n",
      "        self.statistical_analysis = lightwood.data.statistical_analysis(\n",
      "            data, self.dtype_dict, {}, self.problem_definition\n",
      "        )\n",
      "\n",
      "        # Instantiate post-training evaluation\n",
      "        self.analysis_blocks = [\n",
      "            ICP(\n",
      "                fixed_significance=None,\n",
      "                confidence_normalizer=False,\n",
      "                positive_domain=self.statistical_analysis.positive_domain,\n",
      "            ),\n",
      "            AccStats(deps=[\"ICP\"]),\n",
      "            ConfStats(deps=[\"ICP\"]),\n",
      "        ]\n",
      "\n",
      "    @timed\n",
      "    def preprocess(self, data: pd.DataFrame) -> pd.DataFrame:\n",
      "        # Preprocess and clean data\n",
      "\n",
      "        log.info(\"Cleaning the data\")\n",
      "        self.imputers = {}\n",
      "        data = cleaner(\n",
      "            data=data,\n",
      "            pct_invalid=self.problem_definition.pct_invalid,\n",
      "            identifiers=self.identifiers,\n",
      "            dtype_dict=self.dtype_dict,\n",
      "            target=self.target,\n",
      "            mode=self.mode,\n",
      "            imputers=self.imputers,\n",
      "            timeseries_settings=self.problem_definition.timeseries_settings,\n",
      "            anomaly_detection=self.problem_definition.anomaly_detection,\n",
      "        )\n",
      "\n",
      "        # Time-series blocks\n",
      "\n",
      "        return data\n",
      "\n",
      "    @timed\n",
      "    def split(self, data: pd.DataFrame) -> Dict[str, pd.DataFrame]:\n",
      "        # Split the data into training/testing splits\n",
      "\n",
      "        log.info(\"Splitting the data into train/test\")\n",
      "        train_test_data = MyCustomSplitter.MySplitter(\n",
      "            data=data, pct_train=0.8, pct_dev=0.1, seed=1, target=self.target\n",
      "        )\n",
      "\n",
      "        return train_test_data\n",
      "\n",
      "    @timed\n",
      "    def prepare(self, data: Dict[str, pd.DataFrame]) -> None:\n",
      "        # Prepare encoders to featurize data\n",
      "\n",
      "        self.mode = \"train\"\n",
      "\n",
      "        if self.statistical_analysis is None:\n",
      "            raise Exception(\"Please run analyze_data first\")\n",
      "\n",
      "        # Column to encoder mapping\n",
      "        self.encoders = {\n",
      "            \"Class\": BinaryEncoder(\n",
      "                is_target=True, target_weights=self.statistical_analysis.target_weights\n",
      "            ),\n",
      "            \"Time\": NumericEncoder(),\n",
      "            \"V1\": NumericEncoder(),\n",
      "            \"V2\": NumericEncoder(),\n",
      "            \"V3\": NumericEncoder(),\n",
      "            \"V4\": NumericEncoder(),\n",
      "            \"V5\": NumericEncoder(),\n",
      "            \"V6\": NumericEncoder(),\n",
      "            \"V7\": NumericEncoder(),\n",
      "            \"V8\": NumericEncoder(),\n",
      "            \"V9\": NumericEncoder(),\n",
      "            \"V10\": NumericEncoder(),\n",
      "            \"V11\": NumericEncoder(),\n",
      "            \"V12\": NumericEncoder(),\n",
      "            \"V13\": NumericEncoder(),\n",
      "            \"V14\": NumericEncoder(),\n",
      "            \"V15\": NumericEncoder(),\n",
      "            \"V16\": NumericEncoder(),\n",
      "            \"V17\": NumericEncoder(),\n",
      "            \"V18\": NumericEncoder(),\n",
      "            \"V19\": NumericEncoder(),\n",
      "            \"V20\": NumericEncoder(),\n",
      "            \"V21\": NumericEncoder(),\n",
      "            \"V22\": NumericEncoder(),\n",
      "            \"V23\": NumericEncoder(),\n",
      "            \"V24\": NumericEncoder(),\n",
      "            \"V25\": NumericEncoder(),\n",
      "            \"V26\": NumericEncoder(),\n",
      "            \"V27\": NumericEncoder(),\n",
      "            \"V28\": NumericEncoder(),\n",
      "            \"Amount\": NumericEncoder(),\n",
      "        }\n",
      "\n",
      "        # Prepare the training + dev data\n",
      "        concatenated_train_dev = pd.concat([data[\"train\"], data[\"dev\"]])\n",
      "\n",
      "        encoder_prepping_dict = {}\n",
      "\n",
      "        # Prepare encoders that do not require learned strategies\n",
      "        for col_name, encoder in self.encoders.items():\n",
      "            if col_name != self.target and not encoder.is_trainable_encoder:\n",
      "                encoder_prepping_dict[col_name] = [\n",
      "                    encoder,\n",
      "                    concatenated_train_dev[col_name],\n",
      "                    \"prepare\",\n",
      "                ]\n",
      "\n",
      "        # Setup parallelization\n",
      "        parallel_prepped_encoders = mut_method_call(encoder_prepping_dict)\n",
      "        for col_name, encoder in parallel_prepped_encoders.items():\n",
      "            self.encoders[col_name] = encoder\n",
      "\n",
      "        # Prepare the target\n",
      "        if self.target not in parallel_prepped_encoders:\n",
      "            if self.encoders[self.target].is_trainable_encoder:\n",
      "                self.encoders[self.target].prepare(\n",
      "                    data[\"train\"][self.target], data[\"dev\"][self.target]\n",
      "                )\n",
      "            else:\n",
      "                self.encoders[self.target].prepare(\n",
      "                    pd.concat([data[\"train\"], data[\"dev\"]])[self.target]\n",
      "                )\n",
      "\n",
      "        # Prepare any non-target encoders that are learned\n",
      "        for col_name, encoder in self.encoders.items():\n",
      "            if col_name != self.target and encoder.is_trainable_encoder:\n",
      "                priming_data = pd.concat([data[\"train\"], data[\"dev\"]])\n",
      "                kwargs = {}\n",
      "                if self.dependencies[col_name]:\n",
      "                    kwargs[\"dependency_data\"] = {}\n",
      "                    for col in self.dependencies[col_name]:\n",
      "                        kwargs[\"dependency_data\"][col] = {\n",
      "                            \"original_type\": self.dtype_dict[col],\n",
      "                            \"data\": priming_data[col],\n",
      "                        }\n",
      "\n",
      "                # If an encoder representation requires the target, provide priming data\n",
      "                if hasattr(encoder, \"uses_target\"):\n",
      "                    kwargs[\"encoded_target_values\"] = self.encoders[self.target].encode(\n",
      "                        priming_data[self.target]\n",
      "                    )\n",
      "\n",
      "                encoder.prepare(\n",
      "                    data[\"train\"][col_name], data[\"dev\"][col_name], **kwargs\n",
      "                )\n",
      "\n",
      "    @timed\n",
      "    def featurize(self, split_data: Dict[str, pd.DataFrame]):\n",
      "        # Featurize data into numerical representations for models\n",
      "\n",
      "        log.info(\"Featurizing the data\")\n",
      "\n",
      "        feature_data = {\n",
      "            key: EncodedDs(self.encoders, data, self.target)\n",
      "            for key, data in split_data.items()\n",
      "            if key != \"stratified_on\"\n",
      "        }\n",
      "\n",
      "        return feature_data\n",
      "\n",
      "    @timed\n",
      "    def fit(self, enc_data: Dict[str, pd.DataFrame]) -> None:\n",
      "        # Fit predictors to estimate target\n",
      "\n",
      "        self.mode = \"train\"\n",
      "\n",
      "        # --------------- #\n",
      "        # Extract data\n",
      "        # --------------- #\n",
      "        # Extract the featurized data into train/dev/test\n",
      "        encoded_train_data = enc_data[\"train\"]\n",
      "        encoded_dev_data = enc_data[\"dev\"]\n",
      "        encoded_test_data = enc_data[\"test\"]\n",
      "\n",
      "        log.info(\"Training the mixers\")\n",
      "\n",
      "        # --------------- #\n",
      "        # Fit Models\n",
      "        # --------------- #\n",
      "        # Assign list of mixers\n",
      "        self.mixers = [\n",
      "            Neural(\n",
      "                fit_on_dev=True,\n",
      "                search_hyperparameters=True,\n",
      "                net=\"DefaultNet\",\n",
      "                stop_after=self.problem_definition.seconds_per_mixer,\n",
      "                target_encoder=self.encoders[self.target],\n",
      "                target=self.target,\n",
      "                dtype_dict=self.dtype_dict,\n",
      "            ),\n",
      "            LightGBM(\n",
      "                fit_on_dev=True,\n",
      "                use_optuna=True,\n",
      "                stop_after=self.problem_definition.seconds_per_mixer,\n",
      "                target=self.target,\n",
      "                dtype_dict=self.dtype_dict,\n",
      "                input_cols=self.input_cols,\n",
      "                target_encoder=self.encoders[self.target],\n",
      "            ),\n",
      "            Regression(\n",
      "                stop_after=self.problem_definition.seconds_per_mixer,\n",
      "                target=self.target,\n",
      "                dtype_dict=self.dtype_dict,\n",
      "                target_encoder=self.encoders[self.target],\n",
      "            ),\n",
      "        ]\n",
      "\n",
      "        # Train mixers\n",
      "        trained_mixers = []\n",
      "        for mixer in self.mixers:\n",
      "            try:\n",
      "                self.fit_mixer(mixer, encoded_train_data, encoded_dev_data)\n",
      "                trained_mixers.append(mixer)\n",
      "            except Exception as e:\n",
      "                log.warning(f\"Exception: {e} when training mixer: {mixer}\")\n",
      "                if True and mixer.stable:\n",
      "                    raise e\n",
      "\n",
      "        # Update mixers to trained versions\n",
      "        self.mixers = trained_mixers\n",
      "\n",
      "        # --------------- #\n",
      "        # Create Ensembles\n",
      "        # --------------- #\n",
      "        log.info(\"Ensembling the mixer\")\n",
      "        # Create an ensemble of mixers to identify best performing model\n",
      "        self.pred_args = PredictionArguments()\n",
      "        # Dirty hack\n",
      "        self.ensemble = BestOf(\n",
      "            ts_analysis=None,\n",
      "            data=encoded_test_data,\n",
      "            args=self.pred_args,\n",
      "            accuracy_functions=self.accuracy_functions,\n",
      "            target=self.target,\n",
      "            mixers=self.mixers,\n",
      "        )\n",
      "        self.supports_proba = self.ensemble.supports_proba\n",
      "\n",
      "    @timed\n",
      "    def fit_mixer(self, mixer, encoded_train_data, encoded_dev_data) -> None:\n",
      "        mixer.fit(encoded_train_data, encoded_dev_data)\n",
      "\n",
      "    @timed\n",
      "    def analyze_ensemble(self, enc_data: Dict[str, pd.DataFrame]) -> None:\n",
      "        # Evaluate quality of fit for the ensemble of mixers\n",
      "\n",
      "        # --------------- #\n",
      "        # Extract data\n",
      "        # --------------- #\n",
      "        # Extract the featurized data into train/dev/test\n",
      "        encoded_train_data = enc_data[\"train\"]\n",
      "        encoded_dev_data = enc_data[\"dev\"]\n",
      "        encoded_test_data = enc_data[\"test\"]\n",
      "\n",
      "        # --------------- #\n",
      "        # Analyze Ensembles\n",
      "        # --------------- #\n",
      "        log.info(\"Analyzing the ensemble of mixers\")\n",
      "        self.model_analysis, self.runtime_analyzer = model_analyzer(\n",
      "            data=encoded_test_data,\n",
      "            train_data=encoded_train_data,\n",
      "            ts_analysis=None,\n",
      "            stats_info=self.statistical_analysis,\n",
      "            tss=self.problem_definition.timeseries_settings,\n",
      "            accuracy_functions=self.accuracy_functions,\n",
      "            predictor=self.ensemble,\n",
      "            target=self.target,\n",
      "            dtype_dict=self.dtype_dict,\n",
      "            analysis_blocks=self.analysis_blocks,\n",
      "        )\n",
      "\n",
      "    @timed\n",
      "    def learn(self, data: pd.DataFrame) -> None:\n",
      "        if self.problem_definition.ignore_features:\n",
      "            log.info(f\"Dropping features: {self.problem_definition.ignore_features}\")\n",
      "            data = data.drop(\n",
      "                columns=self.problem_definition.ignore_features, errors=\"ignore\"\n",
      "            )\n",
      "\n",
      "        self.mode = \"train\"\n",
      "        n_phases = 8 if self.problem_definition.fit_on_all else 7\n",
      "\n",
      "        # Perform stats analysis\n",
      "        log.info(f\"[Learn phase 1/{n_phases}] - Statistical analysis\")\n",
      "        self.analyze_data(data)\n",
      "\n",
      "        # Pre-process the data\n",
      "        log.info(f\"[Learn phase 2/{n_phases}] - Data preprocessing\")\n",
      "        data = self.preprocess(data)\n",
      "\n",
      "        # Create train/test (dev) split\n",
      "        log.info(f\"[Learn phase 3/{n_phases}] - Data splitting\")\n",
      "        train_dev_test = self.split(data)\n",
      "\n",
      "        # Prepare encoders\n",
      "        log.info(f\"[Learn phase 4/{n_phases}] - Preparing encoders\")\n",
      "        self.prepare(train_dev_test)\n",
      "\n",
      "        # Create feature vectors from data\n",
      "        log.info(f\"[Learn phase 5/{n_phases}] - Feature generation\")\n",
      "        enc_train_test = self.featurize(train_dev_test)\n",
      "\n",
      "        # Prepare mixers\n",
      "        log.info(f\"[Learn phase 6/{n_phases}] - Mixer training\")\n",
      "        self.fit(enc_train_test)\n",
      "\n",
      "        # Analyze the ensemble\n",
      "        log.info(f\"[Learn phase 7/{n_phases}] - Ensemble analysis\")\n",
      "        self.analyze_ensemble(enc_train_test)\n",
      "\n",
      "        # ------------------------ #\n",
      "        # Enable model partial fit AFTER it is trained and evaluated for performance with the appropriate train/dev/test splits.\n",
      "        # This assumes the predictor could continuously evolve, hence including reserved testing data may improve predictions.\n",
      "        # SET `json_ai.problem_definition.fit_on_all=False` TO TURN THIS BLOCK OFF.\n",
      "\n",
      "        # Update the mixers with partial fit\n",
      "        if self.problem_definition.fit_on_all:\n",
      "\n",
      "            log.info(f\"[Learn phase 8/{n_phases}] - Adjustment on validation requested\")\n",
      "            self.adjust(\n",
      "                enc_train_test[\"test\"],\n",
      "                ConcatedEncodedDs([enc_train_test[\"train\"], enc_train_test[\"dev\"]]),\n",
      "            )\n",
      "\n",
      "    @timed\n",
      "    def adjust(\n",
      "        self,\n",
      "        train_data: Union[EncodedDs, ConcatedEncodedDs, pd.DataFrame],\n",
      "        dev_data: Optional[Union[EncodedDs, ConcatedEncodedDs, pd.DataFrame]] = None,\n",
      "    ) -> None:\n",
      "        # Update mixers with new information\n",
      "\n",
      "        self.mode = \"train\"\n",
      "\n",
      "        # --------------- #\n",
      "        # Prepare data\n",
      "        # --------------- #\n",
      "        if dev_data is None:\n",
      "            data = (\n",
      "                train_data\n",
      "                if isinstance(train_data, pd.DataFrame)\n",
      "                else train_data.data_frame\n",
      "            )\n",
      "            split = splitter(\n",
      "                data,\n",
      "                self.problem_definition.timeseries_settings,\n",
      "                self.dtype_dict,\n",
      "                self.problem_definition.seed_nr,\n",
      "                pct_train=0.8,\n",
      "                pct_dev=0.2,\n",
      "                pct_test=0,\n",
      "                target=self.target,\n",
      "            )\n",
      "            train_data = split[\"train\"]\n",
      "            dev_data = split[\"dev\"]\n",
      "\n",
      "        if isinstance(dev_data, pd.DataFrame):\n",
      "            dev_data = EncodedDs(self.encoders, dev_data, self.target)\n",
      "\n",
      "        if isinstance(train_data, pd.DataFrame):\n",
      "            train_data = EncodedDs(self.encoders, train_data, self.target)\n",
      "\n",
      "        # --------------- #\n",
      "        # Update/Adjust Mixers\n",
      "        # --------------- #\n",
      "        log.info(\"Updating the mixers\")\n",
      "\n",
      "        for mixer in self.mixers:\n",
      "            mixer.partial_fit(train_data, dev_data)\n",
      "\n",
      "    @timed\n",
      "    def predict(self, data: pd.DataFrame, args: Dict = {}) -> pd.DataFrame:\n",
      "\n",
      "        self.mode = \"predict\"\n",
      "        n_phases = 3 if self.pred_args.all_mixers else 4\n",
      "\n",
      "        if len(data) == 0:\n",
      "            raise Exception(\n",
      "                \"Empty input, aborting prediction. Please try again with some input data.\"\n",
      "            )\n",
      "\n",
      "        log.info(f\"[Predict phase 1/{n_phases}] - Data preprocessing\")\n",
      "        if self.problem_definition.ignore_features:\n",
      "            log.info(f\"Dropping features: {self.problem_definition.ignore_features}\")\n",
      "            data = data.drop(\n",
      "                columns=self.problem_definition.ignore_features, errors=\"ignore\"\n",
      "            )\n",
      "        for col in self.input_cols:\n",
      "            if col not in data.columns:\n",
      "                data[col] = [None] * len(data)\n",
      "\n",
      "        # Pre-process the data\n",
      "        data = self.preprocess(data)\n",
      "\n",
      "        # Featurize the data\n",
      "        log.info(f\"[Predict phase 2/{n_phases}] - Feature generation\")\n",
      "        encoded_ds = self.featurize({\"predict_data\": data})[\"predict_data\"]\n",
      "        encoded_data = encoded_ds.get_encoded_data(include_target=False)\n",
      "\n",
      "        log.info(f\"[Predict phase 3/{n_phases}] - Calling ensemble\")\n",
      "        self.pred_args = PredictionArguments.from_dict(args)\n",
      "        df = self.ensemble(encoded_ds, args=self.pred_args)\n",
      "\n",
      "        if self.pred_args.all_mixers:\n",
      "            return df\n",
      "        else:\n",
      "            log.info(f\"[Predict phase 4/{n_phases}] - Analyzing output\")\n",
      "            insights, global_insights = explain(\n",
      "                data=data,\n",
      "                encoded_data=encoded_data,\n",
      "                predictions=df,\n",
      "                ts_analysis=None,\n",
      "                timeseries_settings=self.problem_definition.timeseries_settings,\n",
      "                positive_domain=self.statistical_analysis.positive_domain,\n",
      "                anomaly_detection=self.problem_definition.anomaly_detection,\n",
      "                analysis=self.runtime_analyzer,\n",
      "                target_name=self.target,\n",
      "                target_dtype=self.dtype_dict[self.target],\n",
      "                explainer_blocks=self.analysis_blocks,\n",
      "                pred_args=self.pred_args,\n",
      "            )\n",
      "            return insights\n",
      "\n"
     ]
    }
   ],
   "source": [
    "json_ai.splitter = {\n",
    "        \"module\": \"MyCustomSplitter.MySplitter\",\n",
    "        \"args\": {\n",
    "            \"data\": \"data\",\n",
    "            \"target\": \"$target\",\n",
    "            \"pct_train\": 0.8,\n",
    "            \"pct_dev\": 0.1,\n",
    "            \"seed\": 1\n",
    "        }\n",
    "    }\n",
    "\n",
    "#Generate python code that fills in your pipeline\n",
    "code = code_from_json_ai(json_ai)\n",
    "\n",
    "print(code)\n",
    "\n",
    "# Save code to a file (Optional)\n",
    "with open('custom_splitter_pipeline.py', 'w') as fp:\n",
    "    fp.write(code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dental-beauty",
   "metadata": {},
   "source": [
    "As you can see, an end-to-end pipeline of our entire ML procedure has been generating. There are several abstracted functions to enable transparency as to what processes your data goes through in order to build these models.\n",
    "\n",
    "The key steps of the pipeline are as follows:\n",
    "\n",
    "(1) Run a **statistical analysis** with `analyze_data` <br>\n",
    "(2) Clean your data with `preprocess` <br>\n",
    "(3) Make a training/dev/testing split with `split` <br>\n",
    "(4) Prepare your feature-engineering pipelines with `prepare` <br>\n",
    "(5) Create your features with `featurize` <br>\n",
    "(6) Fit your predictor models with `fit` <br>\n",
    "\n",
    "You can customize this further if necessary, but you have all the steps necessary to train a model!\n",
    "\n",
    "We recommend familiarizing with these steps by calling the above commands, ideally in order. Some commands (namely `prepare`, `featurize`, and `fit`) do depend on other steps.\n",
    "\n",
    "If you want to omit the individual steps, we recommend your simply call the `learn` method, which compiles all the necessary steps implemented to give your fully trained predictive models starting with unprocessed data! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amended-oklahoma",
   "metadata": {},
   "source": [
    "### 6) Call python to run your code and see your preprocessed outputs\n",
    "\n",
    "Once we have code, we can turn this into a python object by calling `predictor_from_code`. This instantiates the `PredictorInterface` object. \n",
    "\n",
    "This predictor object can be then used to run your pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "organic-london",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-07T23:59:08.592926Z",
     "iopub.status.busy": "2022-07-07T23:59:08.592205Z",
     "iopub.status.idle": "2022-07-07T23:59:08.601099Z",
     "shell.execute_reply": "2022-07-07T23:59:08.600489Z"
    }
   },
   "outputs": [],
   "source": [
    "# Turn the code above into a predictor object\n",
    "predictor = predictor_from_code(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fabulous-prime",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-07T23:59:08.604322Z",
     "iopub.status.busy": "2022-07-07T23:59:08.604095Z",
     "iopub.status.idle": "2022-07-07T23:59:25.167790Z",
     "shell.execute_reply": "2022-07-07T23:59:25.166977Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO:lightwood-2404:Cleaning the data\u001b[0m\n",
      "\u001b[37mDEBUG:lightwood-2404: `preprocess` runtime: 13.84 seconds\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2404:Splitting the data into train/test\u001b[0m\n",
      "\u001b[37mDEBUG:lightwood-2404: `split` runtime: 2.72 seconds\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Pre-process the data\n",
    "cleaned_data = predictor.preprocess(data)\n",
    "train_test_data = predictor.split(cleaned_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "suspended-biography",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-07T23:59:25.171954Z",
     "iopub.status.busy": "2022-07-07T23:59:25.171512Z",
     "iopub.status.idle": "2022-07-07T23:59:26.313526Z",
     "shell.execute_reply": "2022-07-07T23:59:26.312660Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams['font.size']=15\n",
    "f = plt.figure(figsize=(18, 5))\n",
    "\n",
    "ax = f.add_subplot(1,3,1)\n",
    "ax.hist(train_test_data[\"train\"]['Class'], bins = [-0.1, 0.1, 0.9, 1.1], log=True)\n",
    "ax.set_ylabel(\"Log Counts\")\n",
    "ax.set_xticks([0, 1])\n",
    "ax.set_xticklabels([\"0\", \"1\"])\n",
    "ax.set_xlabel(\"Class\")\n",
    "ax.set_title(\"Train:\\nDistribution of Classes\")\n",
    "ax.set_ylim([1, 1e6])\n",
    "\n",
    "ax = f.add_subplot(1,3,2)\n",
    "ax.hist(train_test_data[\"dev\"]['Class'], bins = [-0.1, 0.1, 0.9, 1.1], log=True, color='k')\n",
    "ax.set_ylabel(\"Log Counts\")\n",
    "ax.set_xticks([0, 1])\n",
    "ax.set_xticklabels([\"0\", \"1\"])\n",
    "ax.set_xlabel(\"Class\")\n",
    "ax.set_title(\"Dev:\\nDistribution of Classes\")\n",
    "ax.set_ylim([1, 1e6])\n",
    "\n",
    "\n",
    "ax = f.add_subplot(1,3,3)\n",
    "ax.hist(train_test_data[\"test\"]['Class'], bins = [-0.1, 0.1, 0.9, 1.1], log=True, color='r')\n",
    "ax.set_ylabel(\"Log Counts\")\n",
    "ax.set_xticks([0, 1])\n",
    "ax.set_xticklabels([\"0\", \"1\"])\n",
    "ax.set_xlabel(\"Class\")\n",
    "ax.set_title(\"Test:\\nDistribution of Classes\")\n",
    "ax.set_ylim([1, 1e6])\n",
    "\n",
    "f.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "operational-binary",
   "metadata": {},
   "source": [
    "As you can see, our splitter has greatly increased the representation of the minority class within the training data, but not so for the testing or dev data.\n",
    "\n",
    "We hope this tutorial was informative on how to introduce a **custom splitter method** to your datasets! For more customization tutorials, please check our [documentation](https://lightwood.io/tutorials.html).\n",
    "\n",
    "If you want to download the Jupyter-notebook version of this tutorial, check out the source github location found here: `lightwood/docssrc/source/tutorials/custom_splitter`. "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
